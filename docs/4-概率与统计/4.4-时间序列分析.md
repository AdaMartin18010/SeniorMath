# 时间序列分析

## 概述

时间序列分析是统计推断的重要分支，用于研究随时间变化的数据模式。本模块涵盖平稳性、自相关、ARIMA模型、季节性分解等核心内容，为预测和趋势分析提供理论基础。

## 历史与发展

### 历史背景

- **早期发展**：20世纪初尤尔研究经济时间序列
- **理论完善**：博克斯-詹金斯建立ARIMA模型理论
- **现代发展**：状态空间模型、机器学习方法
- **应用扩展**：经济学、气象学、工程学等

### 数学意义

```lean
-- 时间序列的形式化定义
def time_series (X : ℕ → ℝ) :=
  Xₜ = f(t) + εₜ ∧
  εₜ ~ N(0, σ²)

-- 平稳性定义
def stationarity (X : ℕ → ℝ) :=
  E Xₜ = μ ∧
  V Xₜ = σ² ∧
  Cov(Xₜ, Xₜ₊ₖ) = γ(k)
```

## 平稳性检验

### 基本概念

#### 平稳性定义

```lean
-- 弱平稳性
def weak_stationarity (X : ℕ → ℝ) :=
  (mean_stationarity : E Xₜ = μ) ∧
  (variance_stationarity : V Xₜ = σ²) ∧
  (covariance_stationarity : Cov(Xₜ, Xₜ₊ₖ) = γ(k))

-- 严格平稳性
def strict_stationarity (X : ℕ → ℝ) :=
  ∀ k ∈ ℕ, (Xₜ, Xₜ₊₁, ..., Xₜ₊ₖ) ~ (Xₜ₊ₕ, Xₜ₊ₕ₊₁, ..., Xₜ₊ₕ₊ₖ)
```

#### 算法实现

```rust
// 平稳性检验
struct StationarityTest;

impl StationarityTest {
    fn adf_test(&self, data: &[f64]) -> (f64, f64, bool) {
        let n = data.len();
        let max_lag = (n as f64).powf(1.0/3.0) as usize;
        
        let mut best_adf_stat = f64::INFINITY;
        let mut best_lag = 0;
        
        for lag in 1..=max_lag {
            let adf_stat = self.calculate_adf_statistic(data, lag);
            if adf_stat < best_adf_stat {
                best_adf_stat = adf_stat;
                best_lag = lag;
            }
        }
        
        let p_value = self.adf_p_value(best_adf_stat, n);
        let reject = p_value < 0.05;
        
        (best_adf_stat, p_value, reject)
    }
    
    fn calculate_adf_statistic(&self, data: &[f64], lag: usize) -> f64 {
        let n = data.len();
        let mut diff_data = vec![0.0; n - 1];
        
        for i in 0..(n - 1) {
            diff_data[i] = data[i + 1] - data[i];
        }
        
        let mut lagged_diffs = vec![vec![0.0; n - lag - 1]; lag];
        for i in 0..lag {
            for j in 0..(n - lag - 1) {
                lagged_diffs[i][j] = diff_data[j + i];
            }
        }
        
        let y = &diff_data[lag..];
        let regression = MultipleLinearRegression;
        let coefficients = regression.fit(&lagged_diffs, y);
        
        // 计算ADF统计量
        let se = self.calculate_standard_error(&lagged_diffs, y, &coefficients);
        coefficients[0] / se
    }
    
    fn calculate_standard_error(&self, x: &[Vec<f64>], y: &[f64], coefficients: &[f64]) -> f64 {
        let n = y.len() as f64;
        let p = coefficients.len() as f64;
        
        let residuals: Vec<f64> = x.iter().zip(y.iter())
            .map(|(xi, yi)| {
                let y_pred = coefficients[0];
                for (j, &coef) in coefficients.iter().skip(1).enumerate() {
                    y_pred += coef * xi[j];
                }
                yi - y_pred
            })
            .collect();
        
        let mse = residuals.iter()
            .map(|r| r.powi(2))
            .sum::<f64>() / (n - p);
        
        mse.sqrt()
    }
    
    fn adf_p_value(&self, adf_stat: f64, n: usize) -> f64 {
        // 简化版本，实际应用中需要查表
        if adf_stat < -3.5 {
            0.01
        } else if adf_stat < -3.0 {
            0.05
        } else {
            0.1
        }
    }
    
    fn kpss_test(&self, data: &[f64]) -> (f64, f64, bool) {
        let n = data.len();
        let mean = data.iter().sum::<f64>() / n as f64;
        
        let mut cumulative_sum = vec![0.0; n];
        cumulative_sum[0] = data[0] - mean;
        for i in 1..n {
            cumulative_sum[i] = cumulative_sum[i-1] + (data[i] - mean);
        }
        
        let sum_squared = cumulative_sum.iter()
            .map(|x| x.powi(2))
            .sum::<f64>();
        
        let variance = data.iter()
            .map(|x| (x - mean).powi(2))
            .sum::<f64>() / n as f64;
        
        let kpss_stat = sum_squared / (n as f64 * variance);
        let p_value = self.kpss_p_value(kpss_stat, n);
        let reject = p_value < 0.05;
        
        (kpss_stat, p_value, reject)
    }
    
    fn kpss_p_value(&self, kpss_stat: f64, n: usize) -> f64 {
        // 简化版本，实际应用中需要查表
        if kpss_stat > 0.5 {
            0.01
        } else if kpss_stat > 0.3 {
            0.05
        } else {
            0.1
        }
    }
}
```

## 自相关分析

### 自相关函数

#### 基本定义

```lean
-- 自相关函数
def autocorrelation_function (X : ℕ → ℝ) (k : ℕ) :=
  ρ(k) = Cov(Xₜ, Xₜ₊ₖ) / √(V Xₜ · V Xₜ₊ₖ)

-- 样本自相关函数
def sample_autocorrelation (X : ℕ → ℝ) (k : ℕ) :=
  r(k) = ∑ₜ₌₁ⁿ⁻ᵏ (Xₜ - X̄)(Xₜ₊ₖ - X̄) / ∑ₜ₌₁ⁿ (Xₜ - X̄)²
```

#### 算法实现1

```rust
// 自相关分析
struct AutocorrelationAnalysis;

impl AutocorrelationAnalysis {
    fn autocorrelation_function(&self, data: &[f64], max_lag: usize) -> Vec<f64> {
        let n = data.len();
        let mean = data.iter().sum::<f64>() / n as f64;
        
        let variance = data.iter()
            .map(|x| (x - mean).powi(2))
            .sum::<f64>() / n as f64;
        
        let mut acf = vec![0.0; max_lag + 1];
        acf[0] = 1.0; // 滞后0的自相关为1
        
        for lag in 1..=max_lag {
            let mut numerator = 0.0;
            for t in 0..(n - lag) {
                numerator += (data[t] - mean) * (data[t + lag] - mean);
            }
            acf[lag] = numerator / ((n - lag) as f64 * variance);
        }
        
        acf
    }
    
    fn partial_autocorrelation_function(&self, data: &[f64], max_lag: usize) -> Vec<f64> {
        let acf = self.autocorrelation_function(data, max_lag);
        let mut pacf = vec![0.0; max_lag + 1];
        pacf[0] = 1.0;
        pacf[1] = acf[1];
        
        for k in 2..=max_lag {
            let mut phi = vec![0.0; k];
            phi[k-1] = acf[k];
            
            for j in 1..k {
                let mut sum = 0.0;
                for i in 0..j {
                    sum += phi[i] * acf[k - 1 - i];
                }
                phi[j-1] = sum;
            }
            
            pacf[k] = phi[k-1];
        }
        
        pacf
    }
    
    fn ljung_box_test(&self, data: &[f64], max_lag: usize) -> (f64, f64, bool) {
        let acf = self.autocorrelation_function(data, max_lag);
        let n = data.len();
        
        let q_stat = n * (n + 2) as f64 * 
            (1..=max_lag)
                .map(|k| acf[k].powi(2) / (n - k) as f64)
                .sum::<f64>();
        
        let p_value = self.chi2_distribution_p_value(q_stat, max_lag);
        let reject = p_value < 0.05;
        
        (q_stat, p_value, reject)
    }
    
    fn chi2_distribution_p_value(&self, chi2_stat: f64, df: usize) -> f64 {
        // 简化版本，实际应用中需要使用卡方分布
        0.05
    }
}
```

## ARIMA模型

### AR模型

#### 模型定义

```lean
-- AR(p)模型
def ar_model (X : ℕ → ℝ) (p : ℕ) (φ : ℝᵖ) :=
  Xₜ = c + ∑ᵢ₌₁ᵖ φᵢXₜ₋ᵢ + εₜ ∧
  εₜ ~ N(0, σ²)

-- 平稳性条件
def ar_stationarity (φ : ℝᵖ) :=
  roots_of_characteristic_equation_outside_unit_circle(φ)
```

#### 算法实现2

```rust
// AR模型
struct ARModel;

impl ARModel {
    fn fit(&self, data: &[f64], order: usize) -> Vec<f64> {
        let n = data.len();
        let mut x_matrix = vec![vec![0.0; order]; n - order];
        let mut y_vector = vec![0.0; n - order];
        
        for i in order..n {
            y_vector[i - order] = data[i];
            for j in 0..order {
                x_matrix[i - order][j] = data[i - j - 1];
            }
        }
        
        let regression = MultipleLinearRegression;
        regression.fit(&x_matrix, &y_vector)
    }
    
    fn predict(&self, data: &[f64], coefficients: &[f64], steps: usize) -> Vec<f64> {
        let order = coefficients.len();
        let mut predictions = Vec::new();
        let mut history = data.to_vec();
        
        for _ in 0..steps {
            let mut prediction = coefficients[0]; // 截距项
            for i in 0..order {
                prediction += coefficients[i + 1] * history[history.len() - 1 - i];
            }
            predictions.push(prediction);
            history.push(prediction);
        }
        
        predictions
    }
    
    fn aic(&self, data: &[f64], order: usize) -> f64 {
        let coefficients = self.fit(data, order);
        let n = data.len();
        
        let mut residuals = Vec::new();
        for i in order..n {
            let mut prediction = coefficients[0];
            for j in 0..order {
                prediction += coefficients[j + 1] * data[i - j - 1];
            }
            residuals.push(data[i] - prediction);
        }
        
        let mse = residuals.iter()
            .map(|r| r.powi(2))
            .sum::<f64>() / residuals.len() as f64;
        
        n as f64 * mse.ln() + 2.0 * (order + 1) as f64
    }
}
```

### MA模型

#### 模型定义1

```lean
-- MA(q)模型
def ma_model (X : ℕ → ℝ) (q : ℕ) (θ : ℝᵠ) :=
  Xₜ = μ + εₜ + ∑ᵢ₌₁ᵠ θᵢεₜ₋ᵢ ∧
  εₜ ~ N(0, σ²)

-- 可逆性条件
def ma_invertibility (θ : ℝᵠ) :=
  roots_of_characteristic_equation_outside_unit_circle(θ)
```

#### 算法实现3

```rust
// MA模型
struct MAModel;

impl MAModel {
    fn fit(&self, data: &[f64], order: usize) -> Vec<f64> {
        let n = data.len();
        let mean = data.iter().sum::<f64>() / n as f64;
        
        // 使用矩估计法（简化版本）
        let acf = AutocorrelationAnalysis.autocorrelation_function(data, order);
        let mut theta = vec![0.0; order];
        
        // 使用Yule-Walker方程求解
        for i in 0..order {
            theta[i] = acf[i + 1];
        }
        
        let mut coefficients = vec![mean];
        coefficients.extend(theta);
        
        coefficients
    }
    
    fn predict(&self, data: &[f64], coefficients: &[f64], steps: usize) -> Vec<f64> {
        let order = coefficients.len() - 1;
        let mean = coefficients[0];
        let mut predictions = Vec::new();
        
        // 简化版本，假设未来误差为0
        for _ in 0..steps {
            predictions.push(mean);
        }
        
        predictions
    }
}
```

### ARIMA模型1

#### 模型定义3

```lean
-- ARIMA(p,d,q)模型
def arima_model (X : ℕ → ℝ) (p d q : ℕ) (φ : ℝᵖ) (θ : ℝᵠ) :=
  ∇ᵈXₜ = c + ∑ᵢ₌₁ᵖ φᵢ∇ᵈXₜ₋ᵢ + εₜ + ∑ᵢ₌₁ᵠ θᵢεₜ₋ᵢ ∧
  εₜ ~ N(0, σ²)

-- 差分算子
def difference_operator (X : ℕ → ℝ) (d : ℕ) :=
  ∇Xₜ = Xₜ - Xₜ₋₁ ∧
  ∇ᵈXₜ = ∇(∇ᵈ⁻¹Xₜ)
```

#### 算法实现4

```rust
// ARIMA模型
struct ARIMAModel;

impl ARIMAModel {
    fn fit(&self, data: &[f64], p: usize, d: usize, q: usize) -> (Vec<f64>, Vec<f64>) {
        let mut diff_data = data.to_vec();
        
        // 差分
        for _ in 0..d {
            diff_data = self.difference(&diff_data);
        }
        
        // 拟合ARMA模型
        let ar_coeff = ARModel.fit(&diff_data, p);
        let ma_coeff = MAModel.fit(&diff_data, q);
        
        (ar_coeff, ma_coeff)
    }
    
    fn difference(&self, data: &[f64]) -> Vec<f64> {
        let mut diff_data = Vec::new();
        for i in 1..data.len() {
            diff_data.push(data[i] - data[i-1]);
        }
        diff_data
    }
    
    fn inverse_difference(&self, diff_data: &[f64], initial_value: f64) -> Vec<f64> {
        let mut original_data = vec![initial_value];
        let mut cumulative = initial_value;
        
        for &diff in diff_data {
            cumulative += diff;
            original_data.push(cumulative);
        }
        
        original_data
    }
    
    fn predict(&self, data: &[f64], ar_coeff: &[f64], ma_coeff: &[f64], d: usize, steps: usize) -> Vec<f64> {
        let mut diff_data = data.to_vec();
        
        // 差分
        for _ in 0..d {
            diff_data = self.difference(&diff_data);
        }
        
        // 预测差分序列
        let p = ar_coeff.len() - 1;
        let q = ma_coeff.len() - 1;
        
        let mut diff_predictions = Vec::new();
        let mut history = diff_data.clone();
        let mut errors = vec![0.0; history.len()];
        
        for _ in 0..steps {
            let mut prediction = ar_coeff[0]; // 截距项
            
            // AR项
            for i in 0..p {
                prediction += ar_coeff[i + 1] * history[history.len() - 1 - i];
            }
            
            // MA项
            for i in 0..q {
                prediction += ma_coeff[i + 1] * errors[errors.len() - 1 - i];
            }
            
            diff_predictions.push(prediction);
            history.push(prediction);
            errors.push(0.0); // 假设未来误差为0
        }
        
        // 逆差分
        let initial_value = data[0];
        self.inverse_difference(&diff_predictions, initial_value)
    }
    
    fn auto_arima(&self, data: &[f64], max_p: usize, max_d: usize, max_q: usize) -> (usize, usize, usize) {
        let mut best_aic = f64::INFINITY;
        let mut best_params = (0, 0, 0);
        
        for d in 0..=max_d {
            let mut diff_data = data.to_vec();
            for _ in 0..d {
                diff_data = self.difference(&diff_data);
            }
            
            // 检验平稳性
            let stationarity_test = StationarityTest;
            let (_, _, is_stationary) = stationarity_test.adf_test(&diff_data);
            
            if is_stationary {
                for p in 0..=max_p {
                    for q in 0..=max_q {
                        let aic = self.calculate_aic(&diff_data, p, q);
                        if aic < best_aic {
                            best_aic = aic;
                            best_params = (p, d, q);
                        }
                    }
                }
            }
        }
        
        best_params
    }
    
    fn calculate_aic(&self, data: &[f64], p: usize, q: usize) -> f64 {
        let n = data.len();
        let total_params = p + q + 1;
        
        let mut residuals = Vec::new();
        for i in (p.max(q))..n {
            let mut prediction = 0.0;
            // 简化版本，实际应用中需要更复杂的计算
            residuals.push(data[i] - prediction);
        }
        
        let mse = residuals.iter()
            .map(|r| r.powi(2))
            .sum::<f64>() / residuals.len() as f64;
        
        n as f64 * mse.ln() + 2.0 * total_params as f64
    }
}
```

## 季节性分解

### 分解方法

#### 加法分解

```lean
-- 加法分解模型
def additive_decomposition (X : ℕ → ℝ) :=
  Xₜ = Tₜ + Sₜ + Rₜ ∧
  Tₜ : trend ∧
  Sₜ : seasonal ∧
  Rₜ : residual
```

#### 乘法分解

```lean
-- 乘法分解模型
def multiplicative_decomposition (X : ℕ → ℝ) :=
  Xₜ = Tₜ × Sₜ × Rₜ ∧
  Tₜ : trend ∧
  Sₜ : seasonal ∧
  Rₜ : residual
```

#### 算法实现5

```rust
// 季节性分解
struct SeasonalDecomposition;

impl SeasonalDecomposition {
    fn additive_decompose(&self, data: &[f64], period: usize) -> (Vec<f64>, Vec<f64>, Vec<f64>) {
        let n = data.len();
        
        // 趋势分量（移动平均）
        let trend = self.calculate_trend(data, period);
        
        // 去趋势数据
        let detrended: Vec<f64> = data.iter()
            .zip(trend.iter())
            .map(|(x, t)| x - t)
            .collect();
        
        // 季节性分量
        let seasonal = self.calculate_seasonal(&detrended, period);
        
        // 残差分量
        let residual: Vec<f64> = detrended.iter()
            .zip(seasonal.iter())
            .map(|(d, s)| d - s)
            .collect();
        
        (trend, seasonal, residual)
    }
    
    fn multiplicative_decompose(&self, data: &[f64], period: usize) -> (Vec<f64>, Vec<f64>, Vec<f64>) {
        let n = data.len();
        
        // 趋势分量（移动平均）
        let trend = self.calculate_trend(data, period);
        
        // 去趋势数据
        let detrended: Vec<f64> = data.iter()
            .zip(trend.iter())
            .map(|(x, t)| x / t)
            .collect();
        
        // 季节性分量
        let seasonal = self.calculate_seasonal(&detrended, period);
        
        // 残差分量
        let residual: Vec<f64> = detrended.iter()
            .zip(seasonal.iter())
            .map(|(d, s)| d / s)
            .collect();
        
        (trend, seasonal, residual)
    }
    
    fn calculate_trend(&self, data: &[f64], period: usize) -> Vec<f64> {
        let n = data.len();
        let mut trend = vec![0.0; n];
        
        // 中心移动平均
        let half_period = period / 2;
        for i in half_period..(n - half_period) {
            let sum: f64 = data[(i - half_period)..=(i + half_period)].iter().sum();
            trend[i] = sum / period as f64;
        }
        
        // 处理边界
        for i in 0..half_period {
            let sum: f64 = data[0..=(i + half_period)].iter().sum();
            trend[i] = sum / (i + half_period + 1) as f64;
        }
        
        for i in (n - half_period)..n {
            let sum: f64 = data[(i - half_period)..n].iter().sum();
            trend[i] = sum / (n - i + half_period) as f64;
        }
        
        trend
    }
    
    fn calculate_seasonal(&self, detrended: &[f64], period: usize) -> Vec<f64> {
        let n = detrended.len();
        let mut seasonal_pattern = vec![0.0; period];
        let mut counts = vec![0; period];
        
        // 计算每个季节的平均值
        for i in 0..n {
            let season = i % period;
            seasonal_pattern[season] += detrended[i];
            counts[season] += 1;
        }
        
        for i in 0..period {
            if counts[i] > 0 {
                seasonal_pattern[i] /= counts[i] as f64;
            }
        }
        
        // 调整季节性分量使其和为0（加法分解）
        let seasonal_mean = seasonal_pattern.iter().sum::<f64>() / period as f64;
        for i in 0..period {
            seasonal_pattern[i] -= seasonal_mean;
        }
        
        // 重复季节性模式
        let mut seasonal = Vec::new();
        for i in 0..n {
            seasonal.push(seasonal_pattern[i % period]);
        }
        
        seasonal
    }
}
```

## 实际应用

### 经典问题

#### 股票价格预测

```rust
// 股票价格预测
struct StockPricePrediction;

impl StockPricePrediction {
    fn analyze_stock_data(&self, prices: &[f64]) -> (Vec<f64>, Vec<f64>) {
        // 平稳性检验
        let stationarity_test = StationarityTest;
        let (adf_stat, p_value, is_stationary) = stationarity_test.adf_test(prices);
        
        if !is_stationary {
            // 差分处理
            let diff_prices = self.difference(prices);
            return self.analyze_stock_data(&diff_prices);
        }
        
        // 自相关分析
        let acf_analysis = AutocorrelationAnalysis;
        let acf = acf_analysis.autocorrelation_function(prices, 20);
        let pacf = acf_analysis.partial_autocorrelation_function(prices, 20);
        
        (acf, pacf)
    }
    
    fn difference(&self, data: &[f64]) -> Vec<f64> {
        let mut diff_data = Vec::new();
        for i in 1..data.len() {
            diff_data.push(data[i] - data[i-1]);
        }
        diff_data
    }
    
    fn build_arima_model(&self, prices: &[f64]) -> (usize, usize, usize) {
        let arima = ARIMAModel;
        arima.auto_arima(prices, 5, 2, 5)
    }
    
    fn forecast_prices(&self, prices: &[f64], steps: usize) -> Vec<f64> {
        let (p, d, q) = self.build_arima_model(prices);
        let (ar_coeff, ma_coeff) = ARIMAModel.fit(prices, p, d, q);
        
        ARIMAModel.predict(prices, &ar_coeff, &ma_coeff, d, steps)
    }
}
```

#### 销售预测

```rust
// 销售预测
struct SalesForecasting;

impl SalesForecasting {
    fn seasonal_forecast(&self, sales: &[f64], period: usize) -> Vec<f64> {
        let decomposition = SeasonalDecomposition;
        let (trend, seasonal, _) = decomposition.additive_decompose(sales, period);
        
        // 预测趋势
        let trend_forecast = self.forecast_trend(&trend, 12);
        
        // 重复季节性模式
        let seasonal_forecast: Vec<f64> = (0..12)
            .map(|i| seasonal[i % period])
            .collect();
        
        // 组合预测
        trend_forecast.iter()
            .zip(seasonal_forecast.iter())
            .map(|(t, s)| t + s)
            .collect()
    }
    
    fn forecast_trend(&self, trend: &[f64], steps: usize) -> Vec<f64> {
        let arima = ARIMAModel;
        let (p, d, q) = arima.auto_arima(trend, 3, 1, 3);
        let (ar_coeff, ma_coeff) = arima.fit(trend, p, d, q);
        
        arima.predict(trend, &ar_coeff, &ma_coeff, d, steps)
    }
    
    fn detect_anomalies(&self, sales: &[f64]) -> Vec<bool> {
        let n = sales.len();
        let mean = sales.iter().sum::<f64>() / n as f64;
        let std = (sales.iter()
            .map(|x| (x - mean).powi(2))
            .sum::<f64>() / n as f64).sqrt();
        
        sales.iter()
            .map(|x| (x - mean).abs() > 2.0 * std)
            .collect()
    }
}
```

### 复杂问题

#### 多变量时间序列

```rust
// 多变量时间序列
struct MultivariateTimeSeries;

impl MultivariateTimeSeries {
    fn vector_ar_model(&self, data: &[Vec<f64>], order: usize) -> Vec<Vec<f64>> {
        let n = data.len();
        let p = data[0].len();
        
        let mut coefficient_matrices = Vec::new();
        
        for lag in 1..=order {
            let mut matrix = vec![vec![0.0; p]; p];
            
            // 使用最小二乘法估计系数矩阵
            for i in 0..p {
                for j in 0..p {
                    let mut numerator = 0.0;
                    let mut denominator = 0.0;
                    
                    for t in lag..n {
                        numerator += data[t][i] * data[t - lag][j];
                        denominator += data[t - lag][j].powi(2);
                    }
                    
                    if denominator > 1e-10 {
                        matrix[i][j] = numerator / denominator;
                    }
                }
            }
            
            coefficient_matrices.push(matrix);
        }
        
        coefficient_matrices
    }
    
    fn granger_causality_test(&self, x: &[f64], y: &[f64], max_lag: usize) -> (f64, f64, bool) {
        let n = x.len();
        
        // 无约束模型
        let unrestricted_rss = self.calculate_rss(y, x, max_lag);
        
        // 约束模型（不包括x的滞后项）
        let restricted_rss = self.calculate_restricted_rss(y, max_lag);
        
        let f_stat = ((restricted_rss - unrestricted_rss) / max_lag as f64) / 
                     (unrestricted_rss / (n - 2 * max_lag) as f64);
        
        let p_value = self.f_distribution_p_value(f_stat, max_lag, n - 2 * max_lag);
        let reject = p_value < 0.05;
        
        (f_stat, p_value, reject)
    }
    
    fn calculate_rss(&self, y: &[f64], x: &[f64], lag: usize) -> f64 {
        let n = y.len();
        let mut residuals = Vec::new();
        
        for t in lag..n {
            let mut prediction = 0.0;
            for i in 1..=lag {
                prediction += 0.1 * y[t - i]; // 简化版本
                prediction += 0.1 * x[t - i]; // 简化版本
            }
            residuals.push(y[t] - prediction);
        }
        
        residuals.iter()
            .map(|r| r.powi(2))
            .sum()
    }
    
    fn calculate_restricted_rss(&self, y: &[f64], lag: usize) -> f64 {
        let n = y.len();
        let mut residuals = Vec::new();
        
        for t in lag..n {
            let mut prediction = 0.0;
            for i in 1..=lag {
                prediction += 0.1 * y[t - i]; // 简化版本
            }
            residuals.push(y[t] - prediction);
        }
        
        residuals.iter()
            .map(|r| r.powi(2))
            .sum()
    }
    
    fn f_distribution_p_value(&self, f_stat: f64, df1: usize, df2: usize) -> f64 {
        // 简化版本，实际应用中需要使用F分布
        0.05
    }
}
```

## 教学策略

### 多表征学习

- **符号表征**：数学公式和符号
- **图形表征**：时间序列图、自相关图
- **数值表征**：具体数值和计算
- **物理表征**：实际数据和实验

### 认知负荷管理

- **分步教学**：从简单到复杂
- **渐进复杂**：逐步增加难度
- **多角度验证**：多种方法验证结果

### 错误预防

- **常见错误**：
  - 忽略平稳性检验
  - 混淆相关性和因果关系
  - 过度拟合模型
- **预防策略**：
  - 强调概念理解
  - 多练习和验证
  - 系统化检查

## 评估标准

### 理解层面

- 能否解释时间序列概念
- 能否理解不同模型
- 能否识别适用条件

### 应用层面

- 能否正确进行时间序列分析
- 能否构建预测模型
- 能否解决实际问题

### 创新层面

- 能否发现新的应用
- 能否优化分析方法
- 能否建立新的联系

## 扩展阅读

### 理论扩展

- **状态空间模型**：卡尔曼滤波、状态空间表示
- **频谱分析**：傅里叶变换、功率谱密度
- **非线性时间序列**：混沌理论、神经网络

### 应用扩展

- **金融时间序列**：高频数据、波动率建模
- **信号处理**：滤波、降噪
- **机器学习**：深度学习、循环神经网络

### 历史文献

- 尤尔《时间序列分析》
- 博克斯《时间序列分析》
- 汉密尔顿《时间序列分析》

## 学习资源

### 推荐教材

- 《时间序列分析》- 汉密尔顿
- 《时间序列分析》- 博克斯
- 《应用时间序列分析》- 韦斯

### 在线资源

- Coursera时间序列分析课程
- edX统计学习课程
- MIT OpenCourseWare统计课程

### 实践工具

- R语言：ts, arima函数
- Python：statsmodels, pandas
- SAS：PROC ARIMA

---

*时间序列分析为预测和趋势分析提供了强大的数学工具，是现代统计学和数据科学的重要基础。*

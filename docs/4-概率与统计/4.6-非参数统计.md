# 非参数统计

## 概述

非参数统计是统计推断的重要分支，不依赖于总体分布的具体形式。本模块涵盖秩检验、置换检验、核密度估计、非参数回归等核心内容，为数据分析和统计推断提供理论基础。

## 历史与发展

### 历史背景

- **早期发展**：20世纪初皮尔逊、费希尔建立基础理论
- **理论完善**：威尔科克森、曼-惠特尼发展秩检验
- **现代发展**：核方法、机器学习、大数据分析
- **应用扩展**：医学研究、社会科学、生态学等

### 数学意义

```lean
-- 非参数统计的形式化定义
def nonparametric_statistics (X : sample) (F : distribution) :=
  H₀ : F = F₀ ∧
  H₁ : F ≠ F₀ ∧
  test_statistic : ℝ

-- 秩统计量
def rank_statistic (X : sample) :=
  R(Xᵢ) = #{j : Xⱼ ≤ Xᵢ}
```

## 秩检验

### 威尔科克森符号秩检验

#### 基本概念

```lean
-- 威尔科克森符号秩检验
def wilcoxon_signed_rank_test (X Y : sample) :=
  Dᵢ = Xᵢ - Yᵢ ∧
  Rᵢ = rank(|Dᵢ|) ∧
  W⁺ = ∑ᵢ Rᵢ where Dᵢ > 0 ∧
  W⁻ = ∑ᵢ Rᵢ where Dᵢ < 0
```

#### 算法实现

```rust
// 威尔科克森符号秩检验
struct WilcoxonSignedRankTest;

impl WilcoxonSignedRankTest {
    fn test(&self, x: &[f64], y: &[f64]) -> (f64, f64, bool) {
        let n = x.len();
        let mut differences = Vec::new();
        
        for i in 0..n {
            differences.push(x[i] - y[i]);
        }
        
        // 计算绝对值的秩
        let mut abs_diffs: Vec<(f64, usize)> = differences.iter()
            .enumerate()
            .map(|(i, &diff)| (diff.abs(), i))
            .collect();
        
        abs_diffs.sort_by(|a, b| a.0.partial_cmp(&b.0).unwrap());
        
        let mut ranks = vec![0.0; n];
        let mut current_rank = 1.0;
        let mut i = 0;
        
        while i < n {
            let mut j = i;
            while j < n && (abs_diffs[j].0 - abs_diffs[i].0).abs() < 1e-10 {
                j += 1;
            }
            
            let avg_rank = (current_rank + (j - 1) as f64) / 2.0;
            for k in i..j {
                ranks[abs_diffs[k].1] = avg_rank;
            }
            
            current_rank = j as f64 + 1.0;
            i = j;
        }
        
        // 计算W+和W-
        let mut w_plus = 0.0;
        let mut w_minus = 0.0;
        
        for i in 0..n {
            if differences[i] > 0.0 {
                w_plus += ranks[i];
            } else if differences[i] < 0.0 {
                w_minus += ranks[i];
            }
        }
        
        let test_stat = w_plus.min(w_minus);
        let p_value = self.calculate_p_value(test_stat, n);
        let reject = p_value < 0.05;
        
        (test_stat, p_value, reject)
    }
    
    fn calculate_p_value(&self, test_stat: f64, n: usize) -> f64 {
        // 简化版本，实际应用中需要查表或精确计算
        let expected = n * (n + 1) as f64 / 4.0;
        let variance = n * (n + 1) * (2 * n + 1) as f64 / 24.0;
        let z_score = (test_stat - expected) / variance.sqrt();
        
        if z_score.abs() > 1.96 {
            0.05
        } else {
            0.1
        }
    }
}
```

### 曼-惠特尼U检验

#### 基本概念1

```lean
-- 曼-惠特尼U检验
def mann_whitney_u_test (X Y : sample) :=
  U₁ = n₁n₂ + n₁(n₁+1)/2 - R₁ ∧
  U₂ = n₁n₂ + n₂(n₂+1)/2 - R₂ ∧
  U = min(U₁, U₂)
```

#### 算法实现1

```rust
// 曼-惠特尼U检验
struct MannWhitneyUTest;

impl MannWhitneyUTest {
    fn test(&self, group1: &[f64], group2: &[f64]) -> (f64, f64, bool) {
        let n1 = group1.len();
        let n2 = group2.len();
        
        // 合并数据并计算秩
        let mut all_data = Vec::new();
        for (i, &x) in group1.iter().enumerate() {
            all_data.push((x, 1, i));
        }
        for (i, &x) in group2.iter().enumerate() {
            all_data.push((x, 2, i));
        }
        
        all_data.sort_by(|a, b| a.0.partial_cmp(&b.0).unwrap());
        
        let mut ranks = vec![0.0; all_data.len()];
        let mut current_rank = 1.0;
        let mut i = 0;
        
        while i < all_data.len() {
            let mut j = i;
            while j < all_data.len() && (all_data[j].0 - all_data[i].0).abs() < 1e-10 {
                j += 1;
            }
            
            let avg_rank = (current_rank + (j - 1) as f64) / 2.0;
            for k in i..j {
                ranks[k] = avg_rank;
            }
            
            current_rank = j as f64 + 1.0;
            i = j;
        }
        
        // 计算各组秩和
        let mut r1 = 0.0;
        let mut r2 = 0.0;
        
        for (i, (_, group, _)) in all_data.iter().enumerate() {
            if *group == 1 {
                r1 += ranks[i];
            } else {
                r2 += ranks[i];
            }
        }
        
        // 计算U统计量
        let u1 = n1 as f64 * n2 as f64 + n1 as f64 * (n1 as f64 + 1.0) / 2.0 - r1;
        let u2 = n1 as f64 * n2 as f64 + n2 as f64 * (n2 as f64 + 1.0) / 2.0 - r2;
        let u_stat = u1.min(u2);
        
        let p_value = self.calculate_p_value(u_stat, n1, n2);
        let reject = p_value < 0.05;
        
        (u_stat, p_value, reject)
    }
    
    fn calculate_p_value(&self, u_stat: f64, n1: usize, n2: usize) -> f64 {
        // 简化版本，实际应用中需要查表或精确计算
        let expected = n1 as f64 * n2 as f64 / 2.0;
        let variance = n1 as f64 * n2 as f64 * (n1 as f64 + n2 as f64 + 1.0) / 12.0;
        let z_score = (u_stat - expected) / variance.sqrt();
        
        if z_score.abs() > 1.96 {
            0.05
        } else {
            0.1
        }
    }
}
```

### 克鲁斯卡尔-沃利斯检验

#### 基本概念2

```lean
-- 克鲁斯卡尔-沃利斯检验
def kruskal_wallis_test (groups : list sample) :=
  H = 12/(N(N+1)) * ∑ᵢ Rᵢ²/nᵢ - 3(N+1) ∧
  Rᵢ = rank_sum_of_group_i
```

#### 算法实现2

```rust
// 克鲁斯卡尔-沃利斯检验
struct KruskalWallisTest;

impl KruskalWallisTest {
    fn test(&self, groups: &[Vec<f64>]) -> (f64, f64, bool) {
        let k = groups.len();
        let n: usize = groups.iter().map(|g| g.len()).sum();
        
        // 合并所有数据并排序
        let mut all_data: Vec<(f64, usize)> = groups.iter()
            .enumerate()
            .flat_map(|(group_idx, group)| {
                group.iter().map(|&x| (x, group_idx))
            })
            .collect();
        
        all_data.sort_by(|a, b| a.0.partial_cmp(&b.0).unwrap());
        
        // 计算秩
        let mut ranks = vec![0.0; all_data.len()];
        let mut current_rank = 1.0;
        let mut i = 0;
        
        while i < all_data.len() {
            let mut j = i;
            while j < all_data.len() && (all_data[j].0 - all_data[i].0).abs() < 1e-10 {
                j += 1;
            }
            
            let avg_rank = (current_rank + (j - 1) as f64) / 2.0;
            for k in i..j {
                ranks[k] = avg_rank;
            }
            
            current_rank = j as f64 + 1.0;
            i = j;
        }
        
        // 计算各组秩和
        let mut rank_sums = vec![0.0; k];
        let mut data_idx = 0;
        
        for (group_idx, group) in groups.iter().enumerate() {
            for _ in 0..group.len() {
                rank_sums[group_idx] += ranks[data_idx];
                data_idx += 1;
            }
        }
        
        // 计算H统计量
        let h_stat = 12.0 / (n * (n + 1)) as f64 * 
            rank_sums.iter().enumerate()
                .map(|(i, &sum)| sum.powi(2) / groups[i].len() as f64)
                .sum::<f64>() - 3.0 * (n + 1) as f64;
        
        let p_value = self.chi2_distribution_p_value(h_stat, k - 1);
        let reject = p_value < 0.05;
        
        (h_stat, p_value, reject)
    }
    
    fn chi2_distribution_p_value(&self, chi2_stat: f64, df: usize) -> f64 {
        // 简化版本，实际应用中需要使用卡方分布
        0.05
    }
}
```

## 置换检验

### 基本概念3

```lean
-- 置换检验
def permutation_test (X Y : sample) (T : test_statistic) :=
  T_obs = T(X, Y) ∧
  T_perm = T(X_perm, Y_perm) ∧
  p_value = P(T_perm ≥ T_obs)
```

### 算法实现3

```rust
// 置换检验
struct PermutationTest;

impl PermutationTest {
    fn two_sample_test(&self, group1: &[f64], group2: &[f64], n_permutations: usize) -> (f64, f64, bool) {
        let n1 = group1.len();
        let n2 = group2.len();
        
        // 计算观察统计量
        let mean1 = group1.iter().sum::<f64>() / n1 as f64;
        let mean2 = group2.iter().sum::<f64>() / n2 as f64;
        let t_obs = (mean1 - mean2).abs();
        
        // 合并数据
        let mut all_data = Vec::new();
        all_data.extend_from_slice(group1);
        all_data.extend_from_slice(group2);
        
        let mut extreme_count = 0;
        
        for _ in 0..n_permutations {
            // 随机置换
            self.shuffle(&mut all_data);
            
            let perm_group1 = &all_data[0..n1];
            let perm_group2 = &all_data[n1..];
            
            let perm_mean1 = perm_group1.iter().sum::<f64>() / n1 as f64;
            let perm_mean2 = perm_group2.iter().sum::<f64>() / n2 as f64;
            let t_perm = (perm_mean1 - perm_mean2).abs();
            
            if t_perm >= t_obs {
                extreme_count += 1;
            }
        }
        
        let p_value = extreme_count as f64 / n_permutations as f64;
        let reject = p_value < 0.05;
        
        (t_obs, p_value, reject)
    }
    
    fn correlation_test(&self, x: &[f64], y: &[f64], n_permutations: usize) -> (f64, f64, bool) {
        // 计算观察相关系数
        let r_obs = self.pearson_correlation(x, y);
        
        let mut extreme_count = 0;
        let mut y_perm = y.to_vec();
        
        for _ in 0..n_permutations {
            // 随机置换y
            self.shuffle(&mut y_perm);
            
            let r_perm = self.pearson_correlation(x, &y_perm);
            
            if r_perm.abs() >= r_obs.abs() {
                extreme_count += 1;
            }
        }
        
        let p_value = extreme_count as f64 / n_permutations as f64;
        let reject = p_value < 0.05;
        
        (r_obs, p_value, reject)
    }
    
    fn shuffle(&self, data: &mut [f64]) {
        use rand::seq::SliceRandom;
        data.shuffle(&mut rand::thread_rng());
    }
    
    fn pearson_correlation(&self, x: &[f64], y: &[f64]) -> f64 {
        let n = x.len() as f64;
        let x_mean = x.iter().sum::<f64>() / n;
        let y_mean = y.iter().sum::<f64>() / n;
        
        let numerator: f64 = x.iter().zip(y.iter())
            .map(|(xi, yi)| (xi - x_mean) * (yi - y_mean))
            .sum();
        
        let x_var: f64 = x.iter().map(|xi| (xi - x_mean).powi(2)).sum();
        let y_var: f64 = y.iter().map(|yi| (yi - y_mean).powi(2)).sum();
        
        numerator / (x_var * y_var).sqrt()
    }
}
```

## 核密度估计

### 基本概念4

```lean
-- 核密度估计
def kernel_density_estimation (X : sample) (K : kernel) (h : bandwidth) :=
  f̂(x) = 1/(nh) * ∑ᵢ K((x - Xᵢ)/h)

-- 常用核函数
def gaussian_kernel (x : ℝ) :=
  K(x) = 1/√(2π) * exp(-x²/2)
```

### 算法实现4

```rust
// 核密度估计
struct KernelDensityEstimation;

impl KernelDensityEstimation {
    fn estimate(&self, data: &[f64], x_points: &[f64], bandwidth: f64) -> Vec<f64> {
        let n = data.len() as f64;
        let mut density_estimates = Vec::new();
        
        for &x in x_points {
            let mut density = 0.0;
            
            for &xi in data {
                density += self.gaussian_kernel((x - xi) / bandwidth);
            }
            
            density_estimates.push(density / (n * bandwidth));
        }
        
        density_estimates
    }
    
    fn gaussian_kernel(&self, x: f64) -> f64 {
        (-0.5 * x * x).exp() / (2.0 * std::f64::consts::PI).sqrt()
    }
    
    fn epanechnikov_kernel(&self, x: f64) -> f64 {
        if x.abs() <= 1.0 {
            0.75 * (1.0 - x * x)
        } else {
            0.0
        }
    }
    
    fn uniform_kernel(&self, x: f64) -> f64 {
        if x.abs() <= 1.0 {
            0.5
        } else {
            0.0
        }
    }
    
    fn optimal_bandwidth(&self, data: &[f64]) -> f64 {
        let n = data.len();
        let std_dev = self.calculate_std_dev(data);
        
        // Silverman规则
        1.06 * std_dev * (n as f64).powf(-0.2)
    }
    
    fn calculate_std_dev(&self, data: &[f64]) -> f64 {
        let mean = data.iter().sum::<f64>() / data.len() as f64;
        let variance = data.iter()
            .map(|x| (x - mean).powi(2))
            .sum::<f64>() / data.len() as f64;
        
        variance.sqrt()
    }
    
    fn cross_validation_bandwidth(&self, data: &[f64]) -> f64 {
        let mut best_bandwidth = 0.1;
        let mut min_cv_score = f64::INFINITY;
        
        for h in 1..100 {
            let bandwidth = h as f64 / 100.0;
            let cv_score = self.cross_validation_score(data, bandwidth);
            
            if cv_score < min_cv_score {
                min_cv_score = cv_score;
                best_bandwidth = bandwidth;
            }
        }
        
        best_bandwidth
    }
    
    fn cross_validation_score(&self, data: &[f64], bandwidth: f64) -> f64 {
        let mut total_score = 0.0;
        
        for i in 0..data.len() {
            let mut density = 0.0;
            
            for j in 0..data.len() {
                if i != j {
                    density += self.gaussian_kernel((data[i] - data[j]) / bandwidth);
                }
            }
            
            if density > 0.0 {
                total_score += density.ln();
            }
        }
        
        -total_score
    }
}
```

## 非参数回归

### 局部多项式回归

#### 基本概念5

```lean
-- 局部多项式回归
def local_polynomial_regression (X Y : sample) (x₀ : ℝ) (h : bandwidth) (p : degree) :=
  min_β ∑ᵢ K((Xᵢ - x₀)/h) * (Yᵢ - ∑ⱼ βⱼ(Xᵢ - x₀)ʲ)²
```

#### 算法实现5

```rust
// 局部多项式回归
struct LocalPolynomialRegression;

impl LocalPolynomialRegression {
    fn fit(&self, x: &[f64], y: &[f64], x0: f64, bandwidth: f64, degree: usize) -> Vec<f64> {
        let n = x.len();
        let mut weights = Vec::new();
        
        // 计算权重
        for &xi in x {
            let u = (xi - x0) / bandwidth;
            weights.push(self.gaussian_kernel(u));
        }
        
        // 构建设计矩阵
        let mut design_matrix = vec![vec![0.0; degree + 1]; n];
        for i in 0..n {
            for j in 0..=degree {
                design_matrix[i][j] = (x[i] - x0).powi(j as i32);
            }
        }
        
        // 加权最小二乘
        self.weighted_least_squares(&design_matrix, y, &weights)
    }
    
    fn weighted_least_squares(&self, x: &[Vec<f64>], y: &[f64], weights: &[f64]) -> Vec<f64> {
        let n = x.len();
        let p = x[0].len();
        
        // 加权设计矩阵
        let mut weighted_x = vec![vec![0.0; p]; n];
        let mut weighted_y = vec![0.0; n];
        
        for i in 0..n {
            for j in 0..p {
                weighted_x[i][j] = x[i][j] * weights[i].sqrt();
            }
            weighted_y[i] = y[i] * weights[i].sqrt();
        }
        
        let regression = MultipleLinearRegression;
        regression.fit(&weighted_x, &weighted_y)
    }
    
    fn gaussian_kernel(&self, x: f64) -> f64 {
        (-0.5 * x * x).exp() / (2.0 * std::f64::consts::PI).sqrt()
    }
    
    fn loess_regression(&self, x: &[f64], y: &[f64], span: f64) -> Vec<f64> {
        let n = x.len();
        let mut predictions = Vec::new();
        
        for i in 0..n {
            let x0 = x[i];
            let bandwidth = span * n as f64;
            let coefficients = self.fit(x, y, x0, bandwidth, 1);
            predictions.push(coefficients[0]);
        }
        
        predictions
    }
}
```

### 样条回归

#### 基本概念6

```lean
-- 样条回归
def spline_regression (X Y : sample) (knots : list ℝ) :=
  f(x) = ∑ᵢ βᵢBᵢ(x) ∧
  Bᵢ : B-spline_basis
```

#### 算法实现6

```rust
// 样条回归
struct SplineRegression;

impl SplineRegression {
    fn fit(&self, x: &[f64], y: &[f64], knots: &[f64], degree: usize) -> Vec<f64> {
        let n = x.len();
        let n_basis = knots.len() + degree - 1;
        
        // 构建B样条基函数矩阵
        let mut design_matrix = vec![vec![0.0; n_basis]; n];
        
        for i in 0..n {
            for j in 0..n_basis {
                design_matrix[i][j] = self.b_spline_basis(x[i], j, knots, degree);
            }
        }
        
        let regression = MultipleLinearRegression;
        regression.fit(&design_matrix, y)
    }
    
    fn b_spline_basis(&self, x: f64, j: usize, knots: &[f64], degree: usize) -> f64 {
        if degree == 0 {
            if j < knots.len() - 1 && x >= knots[j] && x < knots[j + 1] {
                1.0
            } else {
                0.0
            }
        } else {
            let mut result = 0.0;
            
            if j < knots.len() - 1 {
                let alpha1 = if knots[j + degree] != knots[j] {
                    (x - knots[j]) / (knots[j + degree] - knots[j])
                } else {
                    0.0
                };
                result += alpha1 * self.b_spline_basis(x, j, knots, degree - 1);
            }
            
            if j + 1 < knots.len() - 1 {
                let alpha2 = if knots[j + degree + 1] != knots[j + 1] {
                    (knots[j + degree + 1] - x) / (knots[j + degree + 1] - knots[j + 1])
                } else {
                    0.0
                };
                result += alpha2 * self.b_spline_basis(x, j + 1, knots, degree - 1);
            }
            
            result
        }
    }
    
    fn natural_spline(&self, x: &[f64], y: &[f64], knots: &[f64]) -> Vec<f64> {
        let degree = 3; // 三次样条
        let coefficients = self.fit(x, y, knots, degree);
        
        // 添加自然边界条件
        let mut natural_coefficients = coefficients.clone();
        // 简化版本，实际应用中需要更复杂的边界条件处理
        
        natural_coefficients
    }
}
```

## 实际应用

### 经典问题

#### 医学研究

```rust
// 医学研究中的非参数检验
struct MedicalResearch;

impl MedicalResearch {
    fn treatment_comparison(&self, control_group: &[f64], treatment_group: &[f64]) -> (f64, f64, bool) {
        let test = MannWhitneyUTest;
        test.test(control_group, treatment_group)
    }
    
    fn before_after_analysis(&self, before: &[f64], after: &[f64]) -> (f64, f64, bool) {
        let test = WilcoxonSignedRankTest;
        test.test(before, after)
    }
    
    fn multiple_treatment_comparison(&self, treatment_groups: &[Vec<f64>]) -> (f64, f64, bool) {
        let test = KruskalWallisTest;
        test.test(treatment_groups)
    }
    
    fn survival_analysis(&self, survival_times: &[f64], events: &[bool]) -> Vec<f64> {
        let mut sorted_data: Vec<(f64, bool)> = survival_times.iter()
            .zip(events.iter())
            .map(|(&time, &event)| (time, event))
            .collect();
        
        sorted_data.sort_by(|a, b| a.0.partial_cmp(&b.0).unwrap());
        
        let mut survival_prob = 1.0;
        let mut survival_curve = Vec::new();
        
        for (time, event) in sorted_data {
            if event {
                survival_curve.push((time, survival_prob));
            }
            // 简化版本，实际应用中需要更复杂的生存分析
        }
        
        survival_curve.iter().map(|(_, prob)| *prob).collect()
    }
}
```

#### 社会科学研究

```rust
// 社会科学研究
struct SocialScienceResearch;

impl SocialScienceResearch {
    fn survey_analysis(&self, responses: &[f64], groups: &[usize]) -> (f64, f64, bool) {
        let mut group_data = Vec::new();
        let max_group = groups.iter().max().unwrap();
        
        for group_id in 0..=*max_group {
            let group_responses: Vec<f64> = responses.iter()
                .zip(groups.iter())
                .filter(|(_, &g)| g == group_id)
                .map(|(r, _)| *r)
                .collect();
            
            if !group_responses.is_empty() {
                group_data.push(group_responses);
            }
        }
        
        let test = KruskalWallisTest;
        test.test(&group_data)
    }
    
    fn correlation_analysis(&self, x: &[f64], y: &[f64]) -> (f64, f64, bool) {
        let test = PermutationTest;
        test.correlation_test(x, y, 1000)
    }
    
    fn distribution_comparison(&self, sample1: &[f64], sample2: &[f64]) -> Vec<f64> {
        let kde = KernelDensityEstimation;
        let bandwidth = kde.optimal_bandwidth(sample1);
        
        let min_x = sample1.iter().chain(sample2.iter()).fold(f64::INFINITY, |a, &b| a.min(b));
        let max_x = sample1.iter().chain(sample2.iter()).fold(f64::NEG_INFINITY, |a, &b| a.max(b));
        
        let x_points: Vec<f64> = (0..100)
            .map(|i| min_x + (max_x - min_x) * i as f64 / 99.0)
            .collect();
        
        let density1 = kde.estimate(sample1, &x_points, bandwidth);
        let density2 = kde.estimate(sample2, &x_points, bandwidth);
        
        density1.iter().zip(density2.iter())
            .map(|(d1, d2)| (d1 - d2).abs())
            .collect()
    }
}
```

### 复杂问题

#### 大数据分析

```rust
// 大数据非参数分析
struct BigDataAnalysis;

impl BigDataAnalysis {
    fn streaming_density_estimation(&self, data_stream: &[f64], window_size: usize) -> Vec<f64> {
        let mut density_estimates = Vec::new();
        let kde = KernelDensityEstimation;
        
        for i in window_size..data_stream.len() {
            let window = &data_stream[(i - window_size)..i];
            let bandwidth = kde.optimal_bandwidth(window);
            
            let x_points = vec![data_stream[i]];
            let density = kde.estimate(window, &x_points, bandwidth);
            density_estimates.push(density[0]);
        }
        
        density_estimates
    }
    
    fn online_rank_test(&self, data_stream: &[f64], reference_sample: &[f64]) -> Vec<(f64, f64)> {
        let mut test_results = Vec::new();
        let test = MannWhitneyUTest;
        
        for i in 100..data_stream.len() {
            let current_sample = &data_stream[(i - 100)..i];
            let (stat, p_value, _) = test.test(current_sample, reference_sample);
            test_results.push((stat, p_value));
        }
        
        test_results
    }
    
    fn adaptive_bandwidth_selection(&self, data: &[f64], subsample_size: usize) -> f64 {
        let mut bandwidths = Vec::new();
        let kde = KernelDensityEstimation;
        
        for _ in 0..10 {
            let mut subsample = Vec::new();
            for _ in 0..subsample_size {
                let idx = rand::random::<usize>() % data.len();
                subsample.push(data[idx]);
            }
            
            let bandwidth = kde.cross_validation_bandwidth(&subsample);
            bandwidths.push(bandwidth);
        }
        
        bandwidths.iter().sum::<f64>() / bandwidths.len() as f64
    }
}
```

## 教学策略

### 多表征学习

- **符号表征**：数学公式和符号
- **图形表征**：分布图、检验统计量图
- **数值表征**：具体数值和计算
- **物理表征**：实际数据和实验

### 认知负荷管理

- **分步教学**：从简单到复杂
- **渐进复杂**：逐步增加难度
- **多角度验证**：多种方法验证结果

### 错误预防

- **常见错误**：
  - 混淆参数和非参数方法
  - 忽略分布假设
  - 误解检验结果
- **预防策略**：
  - 强调概念理解
  - 多练习和验证
  - 系统化检查

## 评估标准

### 理解层面

- 能否解释非参数统计概念
- 能否理解不同非参数方法
- 能否识别适用条件

### 应用层面

- 能否正确进行非参数检验
- 能否构建非参数模型
- 能否解决实际问题

### 创新层面

- 能否发现新的应用
- 能否优化非参数方法
- 能否建立新的联系

## 扩展阅读

### 理论扩展

- **稳健统计**：M估计、L估计
- **高维非参数**：稀疏性、正则化
- **贝叶斯非参数**：高斯过程、狄利克雷过程

### 应用扩展

- **机器学习**：核方法、支持向量机
- **数据科学**：大数据分析、流式数据
- **生物统计**：生存分析、临床试验

### 历史文献

- 皮尔逊《统计方法》
- 费希尔《统计推断》
- 威尔科克森《秩和检验》

## 学习资源

### 推荐教材

- 《非参数统计》- 霍兰德
- 《应用非参数统计》- 西格尔
- 《非参数方法》- 莱曼

### 在线资源

- Coursera非参数统计课程
- edX数据科学课程
- MIT OpenCourseWare统计课程

### 实践工具

- R语言：wilcox.test, ks.test
- Python：scipy.stats
- SAS：PROC NPAR1WAY

---

*非参数统计为数据分析和统计推断提供了强大的数学工具，是现代统计学和数据科学的重要基础。*
